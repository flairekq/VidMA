{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1678534981324,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "qMvZUdHqAJ99"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYmmw9FLcktk"
   },
   "source": [
    "Please change the path to a suitable one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3863,
     "status": "ok",
     "timestamp": 1678534985184,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "2gTrMSAqDL6k",
    "outputId": "90e4d9b4-76a8-44ec-e1c5-b24b081e3657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "current_directory = \"/data\"\n",
    "os.chdir(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35566,
     "status": "ok",
     "timestamp": 1678535020744,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "hCuoWxrZVf0I",
    "outputId": "2b051ec8-c0ae-43bd-9ee8-65e3f72b96b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement ntlk (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for ntlk\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: num2words in /usr/local/lib/python3.9/dist-packages (0.5.12)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.9/dist-packages (from num2words) (0.6.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.9/dist-packages (0.18.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.9/dist-packages (0.20.9)\n",
      "Requirement already satisfied: Levenshtein==0.20.9 in /usr/local/lib/python3.9/dist-packages (from python-Levenshtein) (0.20.9)\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.9/dist-packages (from Levenshtein==0.20.9->python-Levenshtein) (2.13.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ntlk\n",
    "!pip install num2words\n",
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1678535022194,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "DJxa8D2k_qsg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag, ne_chunk\n",
    "from nltk import RegexpParser\n",
    "from nltk import Tree\n",
    "\n",
    "import re\n",
    "import num2words\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 699,
     "status": "ok",
     "timestamp": 1678535022869,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "2lm2HNfGVwuF",
    "outputId": "e201f4a2-f51f-418f-f619-d0f6b317d3f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKq5LDsw1yIw"
   },
   "source": [
    "Creation of Product and Brand Lexicon to better identify products in the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1678535023542,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "DV38rwx_kSa0"
   },
   "outputs": [],
   "source": [
    "nyka_df = pd.read_csv(\"nyka.csv\",encoding = \"ISO-8859-1\")\n",
    "sephora_old_df = pd.read_csv(\"sephora.csv\")\n",
    "sephora_old2_df = pd.read_csv(\"sephora_website_dataset.csv\")\n",
    "sephora_new_df = pd.read_csv(\"products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1678535023543,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "-sPe6hewCAgM"
   },
   "outputs": [],
   "source": [
    "def remove_non_ascii(text):\n",
    "  return re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "\n",
    "def clean(text): \n",
    "  #replace number with word\n",
    "  text = re.sub(r\"(\\d+)\", lambda x: num2words.num2words(int(x.group(0))), text)\n",
    "  #replace & with and \n",
    "  text = re.sub(\"&\", \"and\", text)\n",
    "  text = re.sub(\"%\", \"percent\", text)\n",
    "  #remove non-ascii characters -- to remove foreign lang characters\n",
    "  text = remove_non_ascii(text)\n",
    "  #keep alphabets only -- remove all characters \n",
    "  text = re.sub(r'[^a-zA-Z ]+', '', text)\n",
    "  #lowercase\n",
    "  return text.lower()\n",
    "\n",
    "#Creation of Product Lexicon\n",
    "sephora_new_df_product_list = sephora_new_df[\"cleaned_product_name\"].to_list()\n",
    "product_lexicon_list = list(set(sephora_new_df_product_list))\n",
    "\n",
    "#Creation of Brand Lexicon\n",
    "sephora_new_df_brand_list = sephora_new_df[\"brand\"].to_list()\n",
    "brand_lexicon_list = list(set(sephora_new_df_brand_list))\n",
    "\n",
    "#Cleaning\n",
    "cleaned_product_list = [clean(txt) for txt in product_lexicon_list]\n",
    "cleaned_brand_list = [clean(txt) for txt in brand_lexicon_list]\n",
    "\n",
    "#Output to DF\n",
    "product_lexicon_df = pd.DataFrame({'Product':cleaned_product_list})\n",
    "brand_lexicon_df = pd.DataFrame({'Brand':cleaned_brand_list})\n",
    "\n",
    "#Save as CSV\n",
    "product_lexicon_df.to_csv(\"Product Lexicon.csv\", index=False)\n",
    "brand_lexicon_df.to_csv(\"Brand Lexicon.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvEDxeLvel-0"
   },
   "source": [
    "Analyse Category JSON to create a Cosmetics Dictionary to identify words that identify makeup products e.g. \"lipstick\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1678535023544,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "WV_s89NZpphN"
   },
   "outputs": [],
   "source": [
    "with open('categories.json', 'r') as f:\n",
    "  cosmetics_categories = json.load(f)\n",
    "\n",
    "#Process categories.json\n",
    "category_lexicon_str = \"\"\n",
    "for key in cosmetics_categories:\n",
    "  sub_category = cosmetics_categories[key]\n",
    "  for product_cat_key in sub_category:\n",
    "    product_cat_key = re.sub(\"&\", \" \", product_cat_key)\n",
    "    product_cat_key = re.sub(r'[^a-zA-Z ]+', ' ', product_cat_key)\n",
    "    product_cat_key = product_cat_key.lower()\n",
    "    category_lexicon_str += \" \" + product_cat_key.lower()\n",
    "\n",
    "cleaned_category_lexicon = list(set(nltk.word_tokenize(category_lexicon_str)))\n",
    "cleaned_category_lexicon_df = pd.DataFrame({'Category':cleaned_category_lexicon})\n",
    "cleaned_category_lexicon_df = cleaned_category_lexicon_df.drop_duplicates()\n",
    "cleaned_category_lexicon_df.to_csv(\"Category Lexicon.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntIFHR7mUQhu"
   },
   "source": [
    "Intialise Classes for Product Review Identification and Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16515,
     "status": "ok",
     "timestamp": 1678535040053,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "7Bbi5CZNKJa4",
    "outputId": "853f17fb-2857-43f1-d06d-bd62cbfdbd85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: ruptures in /usr/local/lib/python3.9/dist-packages (1.1.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from ruptures) (1.22.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from ruptures) (1.10.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.9/dist-packages (2.2.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (3.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.2.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (0.13.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (0.1.97)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (4.26.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.22.4)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (0.14.1+cu116)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.13.1+cu116)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ruptures\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6214,
     "status": "ok",
     "timestamp": 1678535046264,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "p65uZ4PXR5qE"
   },
   "outputs": [],
   "source": [
    "#For segmentation of transcript into product reviews\n",
    "import ruptures as rpt\n",
    "from ruptures.base import BaseCost\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "class ProductIdentifier:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def remove_non_ascii(self, text):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "\n",
    "  def GetNounsWithNLTK(self, text, chunk_func=ne_chunk):\n",
    "    chunked = chunk_func(pos_tag(word_tokenize(text)))\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for subtree in chunked:\n",
    "      if type(subtree) == Tree:\n",
    "        current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "      elif current_chunk:\n",
    "        named_entity = \" \".join(current_chunk)\n",
    "        if named_entity not in continuous_chunk:\n",
    "          continuous_chunk.append(named_entity)\n",
    "          current_chunk = []\n",
    "      else:\n",
    "        continue\n",
    "\n",
    "    return continuous_chunk\n",
    "\n",
    "  def Check_If_NP_Is_Known_Product(self, np, product_lexicon):\n",
    "    for product in product_lexicon:\n",
    "      if np == product:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "  def Check_If_NP_Has_Product_Indicator(self, np, product_indicators):\n",
    "    for product in product_indicators:\n",
    "      similarity = fuzz.partial_ratio(np.lower(),product.lower())\n",
    "      if similarity >= 95:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "  def Check_If_NP_Is_Product(self, np, product_indicators, product_lexicon):\n",
    "    if self.Check_If_NP_Is_Known_Product(np, product_lexicon):\n",
    "      return True\n",
    "    elif self.Check_If_NP_Has_Product_Indicator(np, product_indicators):\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "\n",
    "  def is_not_substring_of_another_product(self, product, product_lst):\n",
    "    for comparison_product in product_lst:\n",
    "      if product == comparison_product:\n",
    "        continue\n",
    "      if product in comparison_product:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "  def detect_products(self, text, product_indicators, product_lexicon):\n",
    "    #likely to contain the products\n",
    "    nouns_in_transcript = self.GetNounsWithNLTK(text)\n",
    "\n",
    "    #only keep if len > 2 \n",
    "    nouns_in_transcript = list(filter(lambda noun_phrase: len(nltk.word_tokenize(noun_phrase))>=2, nouns_in_transcript))\n",
    "\n",
    "    #keep if match with brand name or contain a product term\n",
    "    nouns_in_transcript = list(filter(lambda noun_phrase: self.Check_If_NP_Is_Product(noun_phrase, product_indicators, product_lexicon), nouns_in_transcript))\n",
    "\n",
    "    #filter the products\n",
    "    nouns_in_transcript = list(filter(lambda product: self.is_not_substring_of_another_product(product, nouns_in_transcript), nouns_in_transcript))\n",
    "\n",
    "    return nouns_in_transcript\n",
    "\n",
    "class CoreferenceResolver:\n",
    "  def __init__(self):\n",
    "    self.predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\")\n",
    "\n",
    "  def get_coreference_resolved_text(self, text):\n",
    "    return self.predictor.coref_resolved(text)\n",
    "\n",
    "#Define cost function for segmentation\n",
    "class CosineCost(BaseCost):\n",
    "    \"\"\"Cost derived from the cosine similarity.\"\"\"\n",
    "\n",
    "    # The 2 following attributes must be specified for compatibility.\n",
    "    model = \"custom_cosine\"\n",
    "    min_size = 2\n",
    "\n",
    "    def fit(self, signal):\n",
    "        \"\"\"Set the internal parameter.\"\"\"\n",
    "        self.signal = signal\n",
    "        self.gram = util.cos_sim(signal, signal)\n",
    "        return self\n",
    "\n",
    "    def error(self, start, end) -> float:\n",
    "        \"\"\"Return the approximation cost on the segment [start:end].\n",
    "\n",
    "        Args:\n",
    "            start (int): start of the segment\n",
    "            end (int): end of the segment\n",
    "        Returns:\n",
    "            segment cost\n",
    "        Raises:\n",
    "            NotEnoughPoints: when the segment is too short (less than `min_size` samples).\n",
    "        \"\"\"\n",
    "        if end - start < self.min_size:\n",
    "            raise NotEnoughPoints\n",
    "        sub_gram = self.gram[start:end, start:end]\n",
    "        val = sub_gram.diagonal().sum()\n",
    "        val -= sub_gram.sum() / (end - start)\n",
    "        return val\n",
    "\n",
    "class TranscriptSegmenter:\n",
    "  def __init__(self):\n",
    "    self.product_identifier = ProductIdentifier()\n",
    "    self.segmentation_cost_function_class = CosineCost()\n",
    "    self.sentence_embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    self.semantic_matching_model = SentenceTransformer('msmarco-distilbert-dot-v5')\n",
    "\n",
    "  def get_sentence_list_from_transcript(self, transcript):\n",
    "    #NLTK sent tokenize chunks different products together so we will manually join sub-clauses by syntax rules\n",
    "    phrases = transcript.split(\"\\n\")\n",
    "    pos_tagged = [pos_tag(nltk.word_tokenize(sentence.lower())) for sentence in phrases]\n",
    "\n",
    "    new_combined_sentence_list = []\n",
    "    for i in range(len(phrases)):\n",
    "      tagged_phrase = pos_tagged[i]\n",
    "      tag_of_first_word = tagged_phrase[0][1]\n",
    "      conjunctions_lst = [\"IN\", \"CC\", \"WDT\", \"TO\", \"WRB\", \"VBG\", \"VBZ\"]\n",
    "      join_sentence = False\n",
    "      if i >= 1:\n",
    "        last_tag_in_prev_sentence = pos_tagged[i-1][-1][1]\n",
    "        if last_tag_in_prev_sentence in conjunctions_lst:\n",
    "          join_sentence = True\n",
    "      if tag_of_first_word in conjunctions_lst:\n",
    "        join_sentence = True\n",
    "\n",
    "      if join_sentence:\n",
    "        #lowercase the first letter to reduce noise when doing NP identification e.g. \"Which is so beautiful\" --> Which to which\n",
    "        sub_clause = phrases[i].replace(phrases[i][0],phrases[i][0].lower(),1)\n",
    "        new_combined_sentence_list[-1] = new_combined_sentence_list[-1] + \" \" + sub_clause\n",
    "      else:\n",
    "        new_combined_sentence_list.append(phrases[i])\n",
    "    return new_combined_sentence_list\n",
    "\n",
    "  def segment_transcript(self, num_products, sentences):\n",
    "    #Find breaks where similarity between chunks is the lowest\n",
    "    embeddings = self.sentence_embedding_model.encode(sentences, convert_to_tensor=True)\n",
    "    n_bkps = num_products-1+2  # e.g. there are 9 change points (10 text segments) + intro and outro\n",
    "    algo = rpt.Dynp(custom_cost=self.segmentation_cost_function_class, min_size=2, jump=1).fit(embeddings)\n",
    "    predicted_bkps = algo.predict(n_bkps=n_bkps)\n",
    "    iteration_lst = predicted_bkps\n",
    "    iteration_lst.insert(0, 0)\n",
    "\n",
    "    chunk_lst = []\n",
    "    for i in range(len(iteration_lst)-1):\n",
    "      chunk = \" \".join(sentences[iteration_lst[i]:iteration_lst[i+1]])\n",
    "      chunk_lst.append(chunk)\n",
    "    return chunk_lst\n",
    "\n",
    "  def split_transcript_by_detected_products(self, review_dict, product_indicators, product_lexicon):\n",
    "    text_transcript = review_dict[\"transcript_text\"]\n",
    "    sentences = self.get_sentence_list_from_transcript(text_transcript)\n",
    "    cleaned_text_transcript = \". \".join(sentences)\n",
    "\n",
    "    #Get an estimate of the number of products for segmentation algo\n",
    "    filtered_product_lst = self.product_identifier.detect_products(cleaned_text_transcript, product_indicators, product_lexicon)\n",
    "\n",
    "    #to remove as channel title and other human names that may be identified as a NP\n",
    "    channel_title = review_dict[\"channel_title\"]\n",
    "    stop_words = channel_title.split()\n",
    "    filtered_product_lst = list(filter(lambda noun_phrase: noun_phrase not in stop_words, filtered_product_lst))\n",
    "\n",
    "    #Too slow -- but it improves the segmentation\n",
    "    #Conduct coresolution to better identify products in each segmented chunk and improve distinction between different chunks\n",
    "    #coresolved_transcript = self.coreference_resolver.get_coreference_resolved_text(cleaned_text_transcript)\n",
    "\n",
    "    #Conduct segmentation\n",
    "    sentences = cleaned_text_transcript.split(\".\")\n",
    "    num_products= len(filtered_product_lst)\n",
    "    chunk_lst = self.segment_transcript(num_products, sentences)\n",
    "\n",
    "    #Use semantic meaning match to match each product to a chunk\n",
    "    corpus = chunk_lst[1:len(chunk_lst)-1] #exclude intro and outro\n",
    "    corpus_embeddings = self.semantic_matching_model.encode(corpus, convert_to_tensor=True)\n",
    "    hits_list = []\n",
    "    for product in filtered_product_lst:\n",
    "      query_embedding = self.semantic_matching_model.encode(product, convert_to_tensor=True)\n",
    "      hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=len(corpus))\n",
    "      for j in range(len(hits[0])):\n",
    "        score = hits[0][j][\"score\"]\n",
    "        corpus_id = hits[0][j][\"corpus_id\"]\n",
    "        hits_list.append((product, corpus_id, score))\n",
    "    hits_list.sort(reverse=False)\n",
    "\n",
    "    #Assign corpus chunks by highest score\n",
    "    product_review_dict = {}\n",
    "    while hits_list:\n",
    "      assignment = hits_list[0]\n",
    "      product_review_dict[assignment[0]] = corpus[assignment[1]]\n",
    "      hits_list = list(filter(lambda x: x[1] != assignment[1] and x[0] != assignment[0], hits_list))\n",
    "\n",
    "    return product_review_dict\n",
    "\n",
    "  #Case of video having chapters\n",
    "\n",
    "  def process_raw_transcript(self, raw_transcript):\n",
    "    text_list = [segment[\"text\"] for segment in raw_transcript]\n",
    "    text = \" \".join(text_list)\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    #remove non-ascii characters -- to remove foreign lang characters\n",
    "    text = self.product_identifier.remove_non_ascii(text)\n",
    "    return text\n",
    "\n",
    "  def split_transcript_by_chapters(self, raw_transcript, chapters):\n",
    "    starts = [round(segment[\"start\"]) for segment in raw_transcript]\n",
    "    product_review_dict = []\n",
    "    chapter_index_list = []\n",
    "    for chapter in chapters:\n",
    "      time_in_sec = round(chapter[\"time_in_min\"] * 60)\n",
    "      #get a index list of chapters \n",
    "      new_insertion_index = bisect.bisect_left(starts, time_in_sec)\n",
    "      chapter_index_list.append(new_insertion_index)\n",
    "    chapter_index_list.append(len(raw_transcript)-1)\n",
    "    for i in range(len(chapter_index_list)-1):\n",
    "      title = chapters[i][\"title\"]\n",
    "      start_index = chapter_index_list[i]\n",
    "      end_index = chapter_index_list[i+1]\n",
    "      product_review_dict.append({title:self.process_raw_transcript(raw_transcript[start_index:end_index])})\n",
    "    \n",
    "    return product_review_dict\n",
    "\n",
    "\n",
    "  def get_product_review_dict(self, review_dict, product_indicator, product_lexicon):\n",
    "    chapters = sample_review_dict[\"chapters\"]\n",
    "    product_review_dict = {}\n",
    "    if chapters == []:\n",
    "      product_review_dict = self.split_transcript_by_detected_products(review_dict, product_indicator, product_lexicon)\n",
    "    else:\n",
    "      raw_transcript = sample_review_dict[\"transcript_raw\"]\n",
    "      product_review_dict = self.split_transcript_by_chapters(raw_transcript, chapters)\n",
    "    return product_review_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1678535046265,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "iDcmoMkdcQgc"
   },
   "outputs": [],
   "source": [
    "product_indicators = pd.read_csv(\"Category Lexicon.csv\")[\"Category\"].to_list()\n",
    "product_lexicon = pd.read_csv(\"Product Lexicon.csv\")[\"Product\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2768,
     "status": "ok",
     "timestamp": 1678535049027,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "j0awCOg7bRdP"
   },
   "outputs": [],
   "source": [
    "product_identifier = ProductIdentifier()\n",
    "#coreference_resolver = CoreferenceResolver()\n",
    "transcript_segmenter = TranscriptSegmenter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWQZZLavdKXK"
   },
   "source": [
    "Load Youtube Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1678535049027,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "6T73mlgljGzM"
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "import json\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1678535049028,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "vdlLE_u4gGbb"
   },
   "outputs": [],
   "source": [
    "#Load data scraped using various Youtube API\n",
    "with open('youtube_data.json', 'r') as f:\n",
    "  reviews = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgOdeisrUC9Q"
   },
   "source": [
    "Demo With Sample Transcript from Youtube video with Chapters -- Segmentation with Chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1678535049028,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "h6Abmwlufm7T",
    "outputId": "52b4960d-9263-4277-db13-b0823340809c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CLEANSING BALM': \"but does not leave a greasy residue. So I put, I have makeup on right now, so I'm going to put it all over my face and my lips. I'm not scared of it, even on my eyes. And then I will take a little bio-friendly pad, 'cause I don't use the cotton pads anymore, and warm water. I put it on the pad, hold it between my fingers like this and do the first layer of removal, and you will see how it takes it off immediately. I used to use very, very hot water. I have a tendency to have more dry skin than oily skin, so that's what I love about this cleanser is it really keeps your face moisturized. And I usually finish with just a regular wash cloth that I wet. And my mother always used to say, moisturizer and cleanser, keeping your face clean. She used to say soap and water, and so I used to use bubbly soap because I thought that that squeaky, dry skin feeling meant that my face was very clean. But because of this, if you notice, just warm water literally took off all the makeup and you can see how clean it makes your face. But it doesn't make your face feel oily, and it doesn't dry it out, that sort of really dry, that kind of dry feeling that I find some soaps do. Sometimes I have to say I... Okay, so I had my eyelashes dyed, so they look like they are still dark, but I have been known to go to sleep with not taking my eye makeup off, which is really bad. But sometimes if I wear a waterproof mascara, I don't take the time at night, but that's not good for you. Although I do look at this routine now, whereas I used to look at it as a chore that I had to do for just, for my work or for something, now I look at it as really self-care, and the ritual of it before I go to sleep at night is actually calming. So you saw the first one, which was the cleanser. The next one is the Chebula, which is an unbelievable active ingredient, and it's called Immunity Serum. And I'm going to take this, it's in a little dropper also by True Botanicals. And I'm going to put it in my hand like this, and then I am going to take this Vitamin C Booster.\"},\n",
       " {'TRUE BOTANICALS VITAMIN C BOOSTER': \"Now, when it's in this powder form, it stays active and fresh a lot longer than when it's already in a product. So what they did was they separated it out and then Vitamin C Booster is really just like, this will stay potent until the last little drop of powder is taken out of this jar. So, I will put a little bit in like that. I mix them together like that. I mix them together. It dissolves entirely. You can put it in with the oil, but I like to put it in with the serum because I feel like it gets a little closer to my face or my skin, or my... I don't know, somehow I just like, I like the way it feels in the serum. So I put it everywhere. But my mom always said, it's good to give yourself a little facial. Little teeny facial every night. It doesn't get tacky or sticky, but I can feel like, oh, now I can feel that I can put another product on it because my skin is already starting to absorb the serum. So I just use the second and third with the booster. The fourth product that I'm going to use is the Pure Radiance Oil by True Botanicals. And look at that color, I love the color of that, and the smell is just heavenly. This Radiance Oil smells like jasmine, it has neroli I think it is, or neroli, and then rose. I put that all over my face, my lips, my nose, even on top of my eyes. Sometimes my daytime is a little quicker than my nighttime. I spend a little bit more time at night taking off my makeup because usually it's being out and out in the elements all day and also I've had makeup on, so I spend more time at night. I see a couple of dermatologists, one mostly for like sunspots and for mole checks and cancer, things like that, and Fraxel. And then I see another one who does like more spot therapy and light therapy on my skin. And I'm willing to try anything. The last product that I'm going to be using is called Resurrection Radiance Eye Cream.\"},\n",
       " {'TRUE BOTANICALS RESURRECTION RADIANCE EYE CREAM': \"Now, I love an eye cream. This one is delicious. It's just, it's thick without being greasy, it is... I like to put a little bit on my hand and I like to warm it up a little bit, and the warmth somehow dissipates it much more smoothly. And I pat first like that. And then sometimes if I'm in the mood in the morning, I usually take one of my little tools and then go like that with it 'cause my eyes kind of can get puffy. They get puffy very easily. I have allergies. If I was going to a desert island, well, I would have to bring a product that had a sunscreen in it. (chuckles) But if I was going to be on a desert island, I think the thing that I would want the most is the Radiance Oil. Because it can be used on my hair, it can be used... I sometimes put it on my lips, I definitely put it on my eyebrows and I feel like I could use multipurpose with it. Although I do really love this eye cream, I might have to sneak the eye cream in to my little sack that I'm taking to the island. (laughs) There's so many trends right now it's hard to keep track of them. I haven't seen anything that's really crazy. I mean, I remember hearing that for bags people were putting Preparation H under their eyes. I have not tried it, but I guess it takes down swelling, (laughs) so maybe I should try it. (laughs) That was probably the craziest, the craziest thing that I've ever heard. Yeah, so I feel like now my face just feels so moisturized. It feels like it's gotten a little attention, but it also feels so clean but not dry, so. So, that is it. You can see how healthy and moisturized and ready to go to bed my face is.\"}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get video information\n",
    "sample_review_id = \"wheUpE7tpKA\"\n",
    "sample_review_dict = reviews[sample_review_id]\n",
    "product_review_dict = transcript_segmenter.get_product_review_dict(sample_review_dict, product_indicators, product_lexicon)\n",
    "product_review_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYdst20SfnL8"
   },
   "source": [
    "Demo with Sample Transcript from Youtube video without Chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6371,
     "status": "ok",
     "timestamp": 1678535055394,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "RjAEmA13zYvq",
    "outputId": "8676cca4-9929-4e97-eba1-9088d7e3413e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Melting Powder Blush': \" I'll show you how to use it by mixing and matching the colors  Perfect for a daily spring makeup  This collection's main product is the Melting Powder Blush  There are eight in total and from No  1 to No  8, they all have different colors which will be launched until next year and there's SUQQU's best product  Signature Color Eyes will come in three types  Then there are four lipsticks  This in total will make up the spring collection in particular, the Melting Powder Blush from my preview of it  it has a very unique form  It's not powder nor is it cream  It's both at the same time  So the blush spreads very well showing off its unique clear and natural pigmentation  It's not powdery and people who don't like cream blushers because the blushers were too oily for them  They will like this!  This product doesn't have oiliness or sticky texture of cream  It just spreads  It feels powdery and like it has been coated on so you can use it to your full satisfaction  I fully recommend it  Another thing is that while spreading it on your skin, it gives a slight shimmer which makes your skin look healthier and clearer  it even looks smoother  This is a natural, clear, shimmering and shiny blusher  Coral  Pink and brown  It comes in different colors so you can pick what you want  The blusher is softer when applied with a brush  Even when using your hand, the color blends so well and naturally  beginners can use it easily and quickly to look natural  So, the form was my favorite part  It spreads well, so it lasts long  Those who wanted to try a cream blusher but couldn't because it felt too oily  I think you will be fully satisfied with this product  The second item of the spring collection is signature Color Eyes\",\n",
       " 'Signature Color Eyes': \" Honestly, I've used so many eyeshadows but I like this product because it's clear and natural looking i like clear looking makeup  that doesn't look stuffy and SUQQU has products that satisfy my needs for such makeup  I love clear and deep looks and SUQQU is reliable in that way  It has just the right amount of glitter!  It shines a light on my skin but not too much if a shadow is powdery  dry, or thick, it won't look natural so it fails to look clear as a base layer but SUQQU products all have the texture that sticks to your skin so it's very clear and elegant and very natural  Then there are glitter shadows and these glitters look so brilliant  I like SUQQU shadows because they have clear and natural pigmentation and it's not powdery because it sticks well! because there are so many bright colors  it's perfect for a daily makeup  Shadows aren't dark or matte, which darkens your face but they have that SUQQU style of making you look elegant  So far I've shown you the SUQQU spring collection and described its products and colors  Some of you may be thinking 'So what's good for me?' 'What do I need to buy?' or similar questions like that  So I have a perfect combo for warm skin tones!  A perfect combo for cool skin tones! how to mix and match for a daily spring makeup that's perfect!  Here is the daily spring makeup style!\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review_id = \"YT79AbvFscI\"\n",
    "sample_review_dict = reviews[sample_review_id]\n",
    "text_transcript = sample_review_dict[\"transcript_text\"]\n",
    "product_review_dict = transcript_segmenter.split_transcript_by_detected_products(sample_review_dict, product_indicators, product_lexicon)\n",
    "product_review_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhc1l0DTcVfM"
   },
   "source": [
    "How it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqzKtHvtbxbn"
   },
   "source": [
    "Get an estimate of the number of products for segmentation algo\n",
    "- Product identification is done by parsing for noun phrases with NLTK\n",
    "- Then filtering this list with a set of product indicators (e.g. lipstick, eyebrow pencil) and product lexicon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2446,
     "status": "ok",
     "timestamp": 1678535057837,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "7fe4K6u8QHZV",
    "outputId": "0f11c7f6-8f9f-409f-cc3c-921569f5275a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Signature Color Eyes', 'Melting Powder Blush']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = transcript_segmenter.get_sentence_list_from_transcript(text_transcript)\n",
    "cleaned_text_transcript = \". \".join(sentences)\n",
    "\n",
    "filtered_product_lst = product_identifier.detect_products(cleaned_text_transcript, product_indicators, product_lexicon)\n",
    "filtered_product_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vsq-Di2sbzz_"
   },
   "source": [
    "Conduct segmentation by converting each sentence into a sentence embedding and finding breakpoints where chunks of sentences have the least cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3481,
     "status": "ok",
     "timestamp": 1678535061315,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "O5ELxEsZU5zU",
    "outputId": "3d132049-4147-499b-e710-5adb0bf5535c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hello! I'm WONJUNGYO, a makeup artist Everyone, spring is on our doorsteps already What does spring remind you of? Real cosmetics manias will be eagerly looking forward to spring because! Cosmetics brands are about to launch their spring collections Today I'm going to unbox SUQQU's 2022 Spring Collection which is my absolute favorite brand\",\n",
       " \"I'll show you how to use it by mixing and matching the colors Perfect for a daily spring makeup This collection's main product is the Melting Powder Blush There are eight in total and from No. 1 to No. 8, they all have different colors which will be launched until next year and there's SUQQU's best product Signature Color Eyes will come in three types Then there are four lipsticks This in total will make up the spring collection in particular, the Melting Powder Blush from my preview of it it has a very unique form It's not powder nor is it cream It's both at the same time So the blush spreads very well showing off its unique clear and natural pigmentation It's not powdery and people who don't like cream blushers because the blushers were too oily for them They will like this! This product doesn't have oiliness or sticky texture of cream It just spreads It feels powdery and like it has been coated on so you can use it to your full satisfaction I fully recommend it Another thing is that while spreading it on your skin, it gives a slight shimmer which makes your skin look healthier and clearer it even looks smoother This is a natural, clear, shimmering and shiny blusher Coral Pink and brown It comes in different colors so you can pick what you want The blusher is softer when applied with a brush Even when using your hand, the color blends so well and naturally beginners can use it easily and quickly to look natural So, the form was my favorite part It spreads well, so it lasts long Those who wanted to try a cream blusher but couldn't because it felt too oily I think you will be fully satisfied with this product The second item of the spring collection is signature Color Eyes\",\n",
       " \"Honestly, I've used so many eyeshadows but I like this product because it's clear and natural looking i like clear looking makeup that doesn't look stuffy and SUQQU has products that satisfy my needs for such makeup I love clear and deep looks and SUQQU is reliable in that way It has just the right amount of glitter! It shines a light on my skin but not too much if a shadow is powdery dry, or thick, it won't look natural so it fails to look clear as a base layer but SUQQU products all have the texture that sticks to your skin so it's very clear and elegant and very natural Then there are glitter shadows and these glitters look so brilliant I like SUQQU shadows because they have clear and natural pigmentation and it's not powdery because it sticks well! because there are so many bright colors it's perfect for a daily makeup Shadows aren't dark or matte, which darkens your face but they have that SUQQU style of making you look elegant So far I've shown you the SUQQU spring collection and described its products and colors Some of you may be thinking 'So what's good for me?' 'What do I need to buy?' or similar questions like that So I have a perfect combo for warm skin tones! A perfect combo for cool skin tones! how to mix and match for a daily spring makeup that's perfect! Here is the daily spring makeup style!\",\n",
       " \"First, use the second color Spread the colorful coral evenly over your eyelids for a beautiful natural color use the first color, yellow gold shadow, on the aegyosal to give a hint of a bright warm color use the fourth khaki shadow as the point color by blocking the front and back and giving a deep shadow Likewise, use the khaki shadow on the under eye, between the lashes This will make the under lashes look lush and your eyes deep Use a large artificial fiber blusher brush to color in your cheeks overall to match the color tone, use the coral with drops of brown for your lips and apply it widely Use No. 107 with orange yellow color to extend the outlines of the lips So the entire lips look natural First use the second shading color for shading the overall eyes to give a deeper look because there's no hint of red, this color is perfect as a shading color for cool skin tones for a more interesting look, use the third orange color on the double eyelids to give a mysterious look Again, use the second shading color on the triangular zone for depth use the ivory shimmer glitter shadow on the aegyosal to make your eyes look bright and spring-like This method is popular these days Dab at the front of your eyes for highlight Finally use the green color to draw the line up This will create a mysterious look when the shading mixes with the green Tap the cheeks lightly to clean up your base makeup Use a wide brush or a brush that comes with the blusher use the artificial fiber brush to apply the blusher lightly to give a cool-tone look as a final touch Use a lilac highlighter to add glow to the C-zone and the front of the eyes Likewise, use a cool-tone lipstick to mix in the colors while reviewing SUQQU products I shared many tips with you Was this video helpful? You must absolutely try the new blusher It's so pretty if you don't often wear colorful makeup you can just use the blusher to give color to your eyes or on the tip of your nose making your nose tip slightly red makes you look younger by doing tone-on-tone makeup your makeup will look brighter Do try it for yourself I'll be back with another helpful video Goodbye~\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conduct segmentation\n",
    "num_products= len(filtered_product_lst)\n",
    "chunk_lst = transcript_segmenter.segment_transcript(num_products, sentences)\n",
    "chunk_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4i9ox_TcNBl"
   },
   "source": [
    "To match each chunk to a product, we will treat this as a retrieval problem and use the product name as a query to find the best chunk that matches the query. We will assign the product-chunk pair with the highest score together first before continuing to assign for the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 7767,
     "status": "ok",
     "timestamp": 1678535069080,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "wz1ndZyFgdh9"
   },
   "outputs": [],
   "source": [
    "#Using Semantic Meaning to extract Product from Chunk\n",
    "model = SentenceTransformer('msmarco-distilbert-dot-v5')\n",
    "corpus = chunk_lst[1:len(chunk_lst)-1] #exclude intro and outro\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1678535069080,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "mjioWkqX66t9",
    "outputId": "14bf5325-c716-48e8-d3fb-94cbdff6a22a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Melting Powder Blush', 0, 0.7779302597045898),\n",
       " ('Melting Powder Blush', 1, 0.7117022275924683),\n",
       " ('Signature Color Eyes', 0, 0.7406129240989685),\n",
       " ('Signature Color Eyes', 1, 0.7078670263290405)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_list = []\n",
    "for product in filtered_product_lst:\n",
    "  query_embedding = model.encode(product, convert_to_tensor=True)\n",
    "  hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=len(corpus))\n",
    "  for j in range(len(hits[0])):\n",
    "    score = hits[0][j][\"score\"]\n",
    "    corpus_id = hits[0][j][\"corpus_id\"]\n",
    "    hits_list.append((product, corpus_id, score))\n",
    "hits_list.sort(reverse=False)\n",
    "hits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1678535069080,
     "user": {
      "displayName": "bel hello",
      "userId": "14145485794765337692"
     },
     "user_tz": -480
    },
    "id": "fwr5ihjg991R",
    "outputId": "9c5be220-0c08-4579-cdc1-4241473cdcc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Melting Powder Blush': \"I'll show you how to use it by mixing and matching the colors Perfect for a daily spring makeup This collection's main product is the Melting Powder Blush There are eight in total and from No. 1 to No. 8, they all have different colors which will be launched until next year and there's SUQQU's best product Signature Color Eyes will come in three types Then there are four lipsticks This in total will make up the spring collection in particular, the Melting Powder Blush from my preview of it it has a very unique form It's not powder nor is it cream It's both at the same time So the blush spreads very well showing off its unique clear and natural pigmentation It's not powdery and people who don't like cream blushers because the blushers were too oily for them They will like this! This product doesn't have oiliness or sticky texture of cream It just spreads It feels powdery and like it has been coated on so you can use it to your full satisfaction I fully recommend it Another thing is that while spreading it on your skin, it gives a slight shimmer which makes your skin look healthier and clearer it even looks smoother This is a natural, clear, shimmering and shiny blusher Coral Pink and brown It comes in different colors so you can pick what you want The blusher is softer when applied with a brush Even when using your hand, the color blends so well and naturally beginners can use it easily and quickly to look natural So, the form was my favorite part It spreads well, so it lasts long Those who wanted to try a cream blusher but couldn't because it felt too oily I think you will be fully satisfied with this product The second item of the spring collection is signature Color Eyes\",\n",
       " 'Signature Color Eyes': \"Honestly, I've used so many eyeshadows but I like this product because it's clear and natural looking i like clear looking makeup that doesn't look stuffy and SUQQU has products that satisfy my needs for such makeup I love clear and deep looks and SUQQU is reliable in that way It has just the right amount of glitter! It shines a light on my skin but not too much if a shadow is powdery dry, or thick, it won't look natural so it fails to look clear as a base layer but SUQQU products all have the texture that sticks to your skin so it's very clear and elegant and very natural Then there are glitter shadows and these glitters look so brilliant I like SUQQU shadows because they have clear and natural pigmentation and it's not powdery because it sticks well! because there are so many bright colors it's perfect for a daily makeup Shadows aren't dark or matte, which darkens your face but they have that SUQQU style of making you look elegant So far I've shown you the SUQQU spring collection and described its products and colors Some of you may be thinking 'So what's good for me?' 'What do I need to buy?' or similar questions like that So I have a perfect combo for warm skin tones! A perfect combo for cool skin tones! how to mix and match for a daily spring makeup that's perfect! Here is the daily spring makeup style!\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assign chunks by highest matching score\n",
    "product_review_dict = {}\n",
    "while hits_list:\n",
    "  assignment = hits_list[0]\n",
    "  product_review_dict[assignment[0]] = corpus[assignment[1]]\n",
    "  hits_list = list(filter(lambda x: x[1] != assignment[1] and x[0] != assignment[0], hits_list))\n",
    "product_review_dict"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMGtwEXodnpoHZTCcNONi/d",
   "provenance": [
    {
     "file_id": "1NnueS5Mm9Ashjv8CZ8srV-Po8Wi-4Tc3",
     "timestamp": 1677679513975
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
